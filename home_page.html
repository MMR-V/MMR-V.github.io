<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>MMR-V: What's Left Unsaid? A Benchmark for Multimodal Deep Reasoning in Videos</title>
  <link rel="icon" type="image/x-icon" href="static/images/github_logo.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">
  <link rel="stylesheet" href="./static/css/video-player.css">
  <link href="https://fonts.googleapis.com/css2?family=Great+Vibes&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Dancing+Script&display=swap" rel="stylesheet">

  <!-- <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bulma.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script> -->
  <script type="text/javascript" src="static/js/sort-table.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/explorer-index.js"></script>
  <script src="./static/js/question_card.js"></script>

  <script src="./static/js/leaderboard_testmini.js"></script>  
  <script src="./data/results/output_folders.js" defer></script>
  <script src="./data/results/model_scores.js" defer></script>

  <script src="./visualizer/data/data_public.js" defer></script>

  <style>
    .no-sort {
        cursor: default;
        pointer-events: none;
        background-image: none !important; /* Remove the sort arrow */
    }
    <style>
/*         table { */
/*             border-collapse: collapse; */
/*             width: 70%; */
/*             font-family: sans-serif; */
/*             font-size: 0.9em; /* Adjusted for potentially many columns */ */
/*         } */
        th, td {
            border: 1px solid #ddd;
            text-align: center; /* Default for numbers */
        }
        th {
            background-color: #f2f2f2;
            text-align: center;
            font-weight: bold;
        }
        td.model-name {
            text-align: center;
            font-weight: bold;
        }
        .section-header th { /* Applied to th within the section header row */
            text-align: center;
            background-color: #e0e0e0;
            font-weight: bold;
            padding-left: 10px;
        }
        .human-row {
            background-color: #e6f3ff; /* Light blue for human row */
        }
        strong {
            font-weight: bold; /* Ensures visibility of explicitly marked best scores */
        }
  </style>
  <link rel="stylesheet" href="styles.css">
</head>
<body>

<header>
  <div class="logo" style="font-family: 'Great Vibes', sans-serif; font-size: 150px; color: white;">MMR-V</div>
        <div class="please-scroll-2" style="top: 130%;">
          <span id="reminder" style="font-size: 40px; color: white;">A Benchmark for Multimodal Deep Reasoning in Videos</span>
<!--   <h1 class="title is-1 publication-title" style="color: white;"> -->
<!--       MMR-V: <em>What's Left Unsaid?</em> A Benchmark for Multimodal Deep Reasoning in Videos -->
<!--   </h1> -->
</header>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <img src="static/images/LOGO_v3.png" alt="Logo" style="height: 1em; vertical-align: middle; margin-right: 0.0em;">
              MMR-V: <em>What's Left Unsaid?</em> A Benchmark for Multimodal Deep Reasoning in Videos
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Kejian Zhu</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Zhuoran Jin</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Hongbang Yuan</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="FOURTH AUTHOR PERSONAL LINK" target="_blank">Jiachun Li</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="FIFTH AUTHOR PERSONAL LINK" target="_blank">Shangqing Tu</a><sup>3</sup>,
              </span>
              <br> <!-- æ·»åŠ æ¢è¡Œ -->
              <span class="author-block">
                <a href="SIXTH AUTHOR PERSONAL LINK" target="_blank">Pengfei Cao</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="SIXTH AUTHOR PERSONAL LINK" target="_blank">Yubo Chen</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="SIXTH AUTHOR PERSONAL LINK" target="_blank">Kang Liu</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="SIXTH AUTHOR PERSONAL LINK" target="_blank">Jun Zhao</a><sup>1,2</sup>,
              </span>
<!--               <span class="author-block"> -->
<!--                 <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Kejian Zhu</a>,</span> -->
<!--                 <span class="author-block"> -->
<!--                   <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Zhuoran Jin</a>,</span> -->
<!--                   <span class="author-block"> -->
<!--                     <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Hongbang Yuan</a> -->
<!--                       <span class="author-block"> -->
<!--                         <a href="FOURTH AUTHOR PERSONAL LINK" target="_blank">Jiachun Li</a>,</span> -->
<!--                         <span class="author-block"> -->
<!--                           <a href="FIFTH AUTHOR PERSONAL LINK" target="_blank">Shangqing Tu</a>,</span> -->
<!--                           <br> -->
<!--                           <span class="author-block"> -->
<!--                             <a href="SIXTH AUTHOR PERSONAL LINK" target="_blank">Pengfei Cao</a> -->
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>School of Artificial Intelligence, University of Chinese Academy of Sciences<br><sup>2</sup>Institute of Automation, Chinese Academy of Sciences <sup>3</sup>Tsinghua University</span>
<!--                     <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://huggingface.co/datasets/JokerJan/MMR-VBench" target="_blank"
                           class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                            <img src="static/images/huggingface_logo-noborder.svg" alt="Hugging Face" style="height: 1em;">
                          </span>
                          <span>Benchmark</span>
                        </a>
                      </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/GaryStack/MMR-V" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Teaser video-->
<!-- <section class="hero teaser">
<!--   <div class="container is-max-desktop"> -->
<!--     <div class="hero-body"> -->
<!--       <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
        <!-- Your video here -->
<!--         <source src="static/videos/banner_video.mp4" -->
<!--         type="video/mp4"> -->
<!--       </video> -->
<!--       <h2 class="subtitle has-text-centered"> -->
<!--         Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus.  -->
<!--       </h2> -->
<!--     </div> -->
<!--   </div> -->
<!-- </section> --> 
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The sequential structure of videos poses a challenge to the ability of multimodal large language models (MLLMs) to locate multi-frame evidence and conduct multimodal reasoning. However, existing video benchmarks mainly focus on understanding tasks, which only require models to match frames mentioned in the question (hereafter referred to as "question frame") and perceive a few adjacent frames. To address this gap, we propose <b>MMR-V: A Benchmark for Multimodal Deep Reasoning in Videos.</b> The benchmark is characterized by the following features. <b>(1) Long-range, multi-frame reasoning</b>: Models are required to infer and analyze evidence frames that may be far from the question frame. <b>(2) Beyond perception</b>: Questions cannot be answered through direct perception alone but require reasoning over hidden information. <b>(3) Reliability</b>: All tasks are manually annotated, referencing extensive real-world user understanding to align with common perceptions. <b>(4) Confusability</b>: Carefully designed distractor annotation strategies to reduce model shortcuts. MMR-V consists of 317 videos and 1,257 tasks. Our experiments reveal that current models still struggle with multi-modal reasoning; even the best-performing model, o4-mini, achieves only 52.5% accuracy. Additionally, current reasoning enhancement strategies (Chain-of-Thought and scaling test-time compute) bring limited gains. Further analysis indicates that the CoT demanded for multi-modal reasoning differs from it in textual reasoning, which partly explains the limited performance gains. We hope that MMR-V can inspire further research into enhancing multi-modal reasoning capabilities.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Benchmark Intro -->
<section class="hero is-small is-light">
  <div style="width: 70%; margin: 0 auto;">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>
      <img src="static/images/data_example_intro_v4_5_16.png" alt="MY ALT TEXT"/>        
      </div>
    </div>
</section>
<!-- End Benchmark Intro -->



<section class="section">
  <div class="container">
    
    <div class="columns is-centered">
      <div class="column is-full has-text-centered content">

        <h2 class="title is-3" id="leaderboard">Leaderboard</h2>
        <div class="content">
          <p class="mt-3">ðŸ“¢ The leaderboard is constantly updating as we are welcoming new submissions!
          </p>
          <p class="mt-3">We consider two test settings: <strong>w/o CoT</strong> and <strong>w/ CoT</strong>.
          </p>
<!--           <div class="word-count"> -->
<!--             <p> -->
<!--               <strong>Short:</strong> 0 ~ 32k words  &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp -->
<!--               <strong>Medium:</strong> 32k ~ 128k words  &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp -->
<!--               <strong>Long:</strong> 128k ~ 2M words -->
<!--             </p> -->
<!--             <p> -->
              By default, this leaderboard is sorted by the overall accuracy w/ CoT, as reasoning models (indicated by ðŸ§ ) natively use CoT to answer questions. The CoT results for non-reasoning models are obtained using our prompt that enforces the model to first generate the CoT and then the final answer. To view other sorted results, please click on the corresponding cell.
<!--             </p> -->
          </div>
          <!-- <table> -->
          <table class="js-sort-table" id="results" style="margin-left: auto; margin-right: auto;">
              <thead>
                  <tr>
                      <th rowspan="2" class="no-sort" style="vertical-align: middle; width: 50px;" data-js-sort-colNum="none"><strong>#</strong></th>
                      <th rowspan="2" class="no-sort" style="vertical-align: middle; width: 280px;" data-js-sort-colNum="none"><strong>Model</strong></th>
                      <th colspan="2" class="no-sort" style="vertical-align: middle; width: 300px;" data-js-sort-colNum="6"><strong>Overall (%)</strong></th>
                      <th colspan="2" class="no-sort" style="vertical-align: middle; width: 300px;" data-js-sort-colNum="8"><strong>Implicit (%)</strong></th>
                      <th colspan="2" class="no-sort" style="vertical-align: middle; width: 300px;" data-js-sort-colNum="10"><strong>Explicit (%)</strong></th> 
                      <th colspan="6" class="no-sort" style="vertical-align: middle; width: 900px;" data-js-sort-colNum="16"><strong>Video Categories</strong></th> 
                  </tr>
                  <tr>
                    <th data-js-sort-colNum="2"><strong>w/o CoT</strong></th>
                    <th data-js-sort-colNum="3"><strong>w/ CoT</strong></th>
                    <th data-js-sort-colNum="4"><strong>w/o CoT</strong></th>
                    <th data-js-sort-colNum="5"><strong>w/ CoT</strong></th>
                    <th data-js-sort-colNum="6"><strong>w/o CoT</strong></th>
                    <th data-js-sort-colNum="7"><strong>w/ CoT</strong></th>
                    <th data-js-sort-colNum="8"><strong>Art</strong></th>
                    <th data-js-sort-colNum="9"><strong>Life</strong></th>
                    <th data-js-sort-colNum="10"><strong>TV</strong></th>
                    <th data-js-sort-colNum="11"><strong>Film</strong></th>
                    <th data-js-sort-colNum="12"><strong>Film</strong></th>
                    <th data-js-sort-colNum="13"><strong>Phi.</strong></th>
                  </tr>
              </thead>
              <tbody>
                  <tr>    
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://huggingface.co/llava-hf/llava-onevision-qwen2-7b-ov-hf" class="ext-link" style="font-size: 16px; margin-left: 5px;">LLaVA-Onevision
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">Bytedance & NTU S-Lab</p>
                      </a></b></td>
                      <td>6.5</td><td class="w-cot-data">8.8</td>
                      <td>7.0</td><td class="w-cot-data">9.6</td>
                      <td>5.4</td><td class="w-cot-data">6.6</td>
                      <td>6.5</td><td>3.4</td><td>9.5</td><td>3.8</td><td>9.8</td><td>1.2</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://huggingface.co/lmms-lab/LLaVA-Video-7B-Qwen2" class="ext-link" style="font-size: 16px; margin-left: 5px;">LLaVA-Video
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">Bytedance & NTU S-Lab</p>
                      </a></b></td>
                      <td>18.4</td><td class="w-cot-data">17.6</td>
                      <td>19.1</td><td class="w-cot-data">18.1</td>
                      <td>15.4</td><td class="w-cot-data">16.3</td>
                      <td>14.4</td><td>11.2</td><td>13.2</td><td>17.4</td><td>21.4</td><td>12.8</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://huggingface.co/Efficient-Large-Model/NVILA-8B-Video/tree/main" class="ext-link" style="font-size: 16px; margin-left: 5px;">NVILA-8B-Video
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">NVIDIA</p>
                      </a></b></td>
                      <td>25.5</td><td class="w-cot-data">25.3</td>
                      <td>26.2</td><td class="w-cot-data">24.2</td>
                      <td>23.9</td><td class="w-cot-data">25.9</td>
                      <td>17.3</td><td>21.3</td><td>23.5</td><td>21.6</td><td>38.0</td><td>21.8</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://huggingface.co/microsoft/Phi-4-multimodal-instruct" class="ext-link" style="font-size: 16px; margin-left: 5px;">Phi-4-multimodal-instruct
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">Microsoft</p>
                      </a></b></td>
                      
                      <td>26.7</td><td class="w-cot-data">27.6</td>
                      <td>29.4</td><td class="w-cot-data">31.2</td>
                      <td>19.4</td><td class="w-cot-data">18.1</td>
                      <td>19.4</td><td>19.2</td><td>25.9</td><td>26.4</td><td>33.9</td><td>24.4</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://huggingface.co/THUDM/cogvlm2-video-llama3-chat/tree/main" class="ext-link" style="font-size: 16px; margin-left: 5px;">Cogvlm2-video-llama3
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">THUDM</p>
                      </a></b></td>
                      <td>25.6</td><td class="w-cot-data">26.1</td>
                      <td>25.4</td><td class="w-cot-data">26.2</td>
                      <td>26.1</td><td class="w-cot-data">25.7</td>
                      <td>15.5</td><td>18.3</td><td>24.7</td><td>19.1</td><td>43.2</td><td>20.8</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct" class="ext-link" style="font-size: 16px; margin-left: 5px;">Qwen2.5-VL-7B
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">Alibaba</p>
                      </a></b></td>
                      <td>30.1</td><td class="w-cot-data">32.4</td>
                      <td>33.7</td><td class="w-cot-data">36.2</td>
                      <td>20.8</td><td class="w-cot-data">22.5</td>
                      <td>20.9</td><td>18.1</td><td>29.6</td><td>21.2</td><td>48.4</td><td>19.8</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://huggingface.co/OpenGVLab/InternVL3-8B" class="ext-link" style="font-size: 16px; margin-left: 5px;">InternVL3-8B
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">Shanghai AI Lab</p>
                      </a></b></td>
                      <td>33.6</td><td class="w-cot-data">32.9</td>
                      <td>35.5</td><td class="w-cot-data">33.4</td>
                      <td>28.6</td><td class="w-cot-data">31.4</td>
                      <td>23.0</td><td>22.6</td><td>31.7</td><td>24.3</td><td>52.9</td><td>23.2</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://huggingface.co/google/gemma-3-12b-it" class="ext-link" style="font-size: 16px; margin-left: 5px;">Gemma-3-12b-it
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">Google</p>
                      </a></b></td>
                      <td>34.0</td><td class="w-cot-data">34.2</td>
                      <td>37.8</td><td class="w-cot-data">37.6</td>
                      <td>24.0</td><td class="w-cot-data">25.4</td>
                      <td>19.4</td><td>24.9</td><td>25.9</td><td>31.3</td><td>51.9</td><td>24.4</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://huggingface.co/OpenGVLab/InternVL2_5-38B" class="ext-link" style="font-size: 16px; margin-left: 5px;">InternVL2.5-38B
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">Shanghai AI Lab</p>
                      </a></b></td>
                      <td>39.9</td><td class="w-cot-data">39.7</td>
                      <td>43.8</td><td class="w-cot-data">43.7</td>
                      <td>29.9</td><td class="w-cot-data">29.4</td>
                      <td>30.4</td><td>28.8</td><td>30.4</td><td>37.2</td><td>57.4</td><td>29.1</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct" class="ext-link" style="font-size: 16px; margin-left: 5px;">Qwen2.5-VL-72B
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">Alibaba</p>
                      </a></b></td>
                      <td>39.1</td><td class="w-cot-data">40.4</td>
                      <td>41.3</td><td class="w-cot-data">42.8</td>
                      <td>33.4</td><td class="w-cot-data">34.3</td>
                      <td>28.9</td><td>28.2</td><td>29.1</td><td>36.5</td><td>55.6</td><td>37.2</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://huggingface.co/google/gemma-3-27b-it" class="ext-link" style="font-size: 16px; margin-left: 5px;">Gemma-3-27b-it
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">Google</p>
                      </a></b></td>
                      <td>42.0</td><td class="w-cot-data">41.1</td>
                      <td>46.5</td><td class="w-cot-data">44.7</td>
                      <td>30.3</td><td class="w-cot-data">32.0</td>
                      <td>31.7</td><td>32.2</td><td>35.5</td><td>41.3</td><td>56.1</td><td>33.7</td>
                  </tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://openai.com/index/hello-gpt-4o/" class="ext-link" style="font-size: 16px; margin-left: 5px;">GPT-4o-mini-2024-07-18
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">OpenAI</p>
                      </a></b></td>
                      <td>34.8</td><td class="w-cot-data">35.2</td>
                      <td>38.0</td><td class="w-cot-data">38.6</td>
                      <td>26.3</td><td class="w-cot-data">26.3</td>
                      <td>29.5</td><td>25.4</td><td>29.6</td><td>33.0</td><td>48.7</td><td>18.6</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/" class="ext-link" style="font-size: 16px; margin-left: 5px;">Gemini-2.0-Flash (16 frames)
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">Google</p>
                      </a></b></td>
                      <td>42.6</td><td class="w-cot-data">44.3</td>
                      <td>44.3</td><td class="w-cot-data">45.9</td>
                      <td>38.3</td><td class="w-cot-data">40.0</td>
                      <td>30.9</td><td>32.2</td><td>40.7</td><td>40.6</td><td>58.5</td><td>24.4</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://www.anthropic.com/news/claude-3-5-sonnet" class="ext-link" style="font-size: 16px; margin-left: 5px;">Claude-3.5-Sonnet-20241022
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">Anthropic</p>
                      </a></b></td>
                      <td>43.3</td><td class="w-cot-data">44.2</td>
                      <td>45.0</td><td class="w-cot-data">46.1</td>
                      <td>38.9</td><td class="w-cot-data">39.1</td>
                      <td>33.8</td><td>31.1</td><td>41.3</td><td>41.3</td><td>55.8</td><td><strong>44.4</strong></td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://openai.com/index/hello-gpt-4o/" class="ext-link" style="font-size: 16px; margin-left: 5px;">GPT-4o-2024-11-20
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">OpenAI</p>
                      </a></b></td>
                      <td>44.0</td><td class="w-cot-data">46.1</td>
                      <td>46.6</td><td class="w-cot-data">46.9</td>
                      <td>37.6</td><td class="w-cot-data">44.0</td>
                      <td>38.1</td><td>37.3</td><td>34.9</td><td>41.0</td><td>61.6</td><td>32.6</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/" class="ext-link" style="font-size: 16px; margin-left: 5px;">Gemini-2.0-Flash-thinking
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">Google</p>
                      </a></b></td>
                      <td>45.0</td><td class="w-cot-data">43.5</td>
                      <td>46.6</td><td class="w-cot-data">46.0</td>
                      <td>40.6</td><td class="w-cot-data">37.1</td>
                      <td>34.5</td><td>31.6</td><td>38.6</td><td>48.3</td><td>60.1</td><td>25.6</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://openai.com/index/gpt-4-1/" class="ext-link" style="font-size: 16px; margin-left: 5px;">GPT-4.1-2025-04-14
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">OpenAI</p>
                      </a></b></td>
                      <td>46.6</td><td class="w-cot-data">48.9</td>
                      <td>49.1</td><td class="w-cot-data">51.7</td>
                      <td>40.3</td><td class="w-cot-data">41.7</td>
                      <td>43.2</td><td>35.6</td><td>43.9</td><td>46.5</td><td>57.1</td><td>34.9</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/" class="ext-link" style="font-size: 16px; margin-left: 5px;">Gemini-2.0-Flash (512 frames)
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">Google</p>
                      </a></b></td>
                      <td>48.0</td><td class="w-cot-data">49.9</td>
                      <td>50.5</td><td class="w-cot-data">52.6</td>
                      <td>41.6</td><td class="w-cot-data">42.9</td> 
                      <td>36.7</td><td>36.7</td><td>39.7</td><td>46.2</td><td>66.7</td><td>31.4</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://blog.google/technology/google-deepmind/google-gemini-updates-io-2025/" class="ext-link" style="font-size: 16px; margin-left: 5px;">Gemini-2.5-Flash
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">Google</p>
                      </a></b></td>
                      <td>51.2</td><td class="w-cot-data">50.5</td>
                      <td>52.9</td><td class="w-cot-data">52.3</td> 
                      <td>46.9</td><td class="w-cot-data">45.3</td>
                      <td>45.3</td><td>39.5</td><td>50.3</td><td>47.9</td><td>65.6</td><td>34.9</td>
                  </tr>
                  <tr>
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><b class=""><a href="https://openai.com/index/introducing-o3-and-o4-mini/" class="ext-link" style="font-size: 16px; margin-left: 5px;">o4-mini-2025-04-16
                      <p style="font-size: 12px; margin-left: 5px; color: #858383;">OpenAI</p>
                      </a></b></td>
                      <td><strong>52.5</strong></td><td class="w-cot-data">52.1</td>
                      <td><strong>54.6</strong></td><td class="w-cot-data"><strong>47.1</strong></td>
                      <td>46.0</td><td class="w-cot-data">48.2</td>
                      <td>40.1</td><td>54.0</td><td>54.0</td><td>51.7</td><td>65.3</td><td>27.9</td>
                  </tr>
                  <tr class="human-row">
                      <td style="vertical-align: middle;"></td>
                      <td style="text-align: left; padding: 2px 10px;"><strong>Human</strong></td>
                      <td>86.0</td><td class="w-cot-data">86.0</td>
                      <td>80.6</td><td class="w-cot-data">80.6</td>
                      <td>91.2</td><td class="w-cot-data">91.2</td>
                      <td>57.7</td><td>92.3</td><td>90.6</td><td>92.3</td><td>90.7</td><td>70.0</td>
                  </tr>
              </tbody>
          </table>
<!--           <p style="margin-top: -20px;"> -->
<!--             <strong style="color: #22a56e; font-size: 18px;" >Green date</strong> indicates the newly added/updated models  &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp -->
<!--             - indicates closed-source models -->
<!--           </p> -->
  
<!--           <p style=" text-align: left;"> -->
<!--             1*. Human accuracy is based on their performance within a 15-minute time limit, after which they are allowed to respond with "I donâ€™t know the answer". This occurred for 8% of the total test data. -->
<!--             </br>2*. Humans achieve 100% accuracy on the 'Easy' subset because it only include questions that humans answer correctly within 10 mins. -->
<!--             </br>3*. Models do not show lower scores on subsets with longer length ranges because the distribution of tasks differs significantly across each length range. -->
<!--             </br>4*. The reported results of Qwen models are evaluated using YaRN with a scaling factor of 4. -->
<!--             </br>5*. Qwen3 models support hybrid thinking. For the w/o CoT results, we evaluate them in non-thinking mode, and for the w/ CoT results, we use thinking mode with a 16K token thinking budget. -->
<!--           </p> -->
  
          <p>
            <strong style="color: #22a56e; font-size: 18px;" >Last Update: 2025-05-15</strong>
          </p>
  
          </div>
  
        </div>
      </div>
  
    </div>
  </section>
<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">MMR-V Example</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="publication-video">
            <iframe width="100%" height="400" 
              src="https://www.youtube.com/embed/OuJ4BBQ0nhc" 
              title="YouTube video player" 
              frameborder="0" 
              allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
              allowfullscreen>
            </iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->



  
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/o4-compare_00.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        Your image here
        <img src="static/images/o4-compare_00.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        Your image here
        <img src="static/images/o4-compare_00.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      Your image here
        <img src="static/images/o4-compare_00.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->



<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
